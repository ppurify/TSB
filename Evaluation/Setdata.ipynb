{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(_data_folder, _result_files):\n",
    "    # Initialize an empty list to store DataFrames\n",
    "    result_dfs = []\n",
    "\n",
    "    # Process each result file\n",
    "    for file in _result_files:\n",
    "        # Extract YT_num and rep from the file name\n",
    "        split_route = file.split(\"_\")\n",
    "        rep_num = split_route[7].split(\".\")[0]\n",
    "\n",
    "        # Read the data from the file into a DataFrame\n",
    "        file_path = os.path.join(_data_folder, file)\n",
    "        df = pd.read_csv(file_path)\n",
    "        df['rep'] = rep_num\n",
    "        df['file_name'] = file.replace(\"result-NoCongestions-\", \"\")\n",
    "        \n",
    "        # Append the DataFrame to the list\n",
    "        result_dfs.append(df)\n",
    "\n",
    "    # Merge all DataFrames\n",
    "    result_df = pd.concat(result_dfs, ignore_index=True)\n",
    "\n",
    "    # Display the merged DataFrame\n",
    "    print(\"result DataFrame:\")\n",
    "    print(result_df)\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_pos = [\n",
    "    (250, 0, 0),\n",
    "    (500, 0, 0),\n",
    "    (0, 0, 50),\n",
    "    (250, 0, 50),\n",
    "    (500, 0, 50),\n",
    "    (750, 0, 50),\n",
    "    (0, 0, 100),\n",
    "    (250, 0, 100),\n",
    "    (500, 0, 100),\n",
    "    (750, 0, 100),\n",
    "    (0, 0, 150),\n",
    "    (250, 0, 150),\n",
    "    (500, 0, 150),\n",
    "    (750, 0, 150),\n",
    "    (250, 0, 200),\n",
    "    (500, 0, 200),\n",
    "    (0, 0, 0),\n",
    "    (750, 0, 0),\n",
    "    (750, 0, 200),\n",
    "    (0, 0, 200)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_df(_data_folder, _other_files):\n",
    "    delay_dfs = []\n",
    "\n",
    "    for file in _other_files:\n",
    "        file_path = os.path.join(_data_folder, file)\n",
    "        _df = pd.read_csv(file_path)\n",
    "        _df['coordinates'] = _df.apply(lambda row: (row['x'], row['y'], row['z']), axis=1)\n",
    "    \n",
    "        # Create 'is_delay_pos' column\n",
    "        _df['is_delay_pos'] = _df['coordinates'].apply(lambda coord: 1 if coord in delay_pos else 0)\n",
    "\n",
    "        if 'now' in file:\n",
    "            _df['Route_id'] = _df['Route_id'] + 100\n",
    "        \n",
    "        # series to dataframe\n",
    "        dist_df = _df['Route_id'].value_counts().rename_axis('Route_id').reset_index(name='dist')\n",
    "        \n",
    "        # Count the number of times is_delay_pos is 1 for each Route_id\n",
    "        delay_count = _df[_df['is_delay_pos'] == 1].groupby('Route_id').size().reset_index(name='delay_count')\n",
    "        delay_count['Truck_id'] = 'Truck-' + delay_count['Route_id'].astype(str)\n",
    "\n",
    "        delay_count['file_name'] = file\n",
    "        # Merge dist_df and delay_count\n",
    "        delay_count = pd.merge(dist_df, delay_count, on='Route_id')\n",
    "\n",
    "        delay_dfs.append(delay_count)\n",
    "\n",
    "    # Merge all DataFrames\n",
    "    delay_df = pd.concat(delay_dfs, ignore_index=True)\n",
    "    print(\"delay DataFrame:\")\n",
    "    print(delay_df)\n",
    "    \n",
    "    return delay_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'original_data'\n",
    "all_files = os.listdir(data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data of simulation results\n",
    "result_files = [file for file in all_files if \"result\" in file]\n",
    "\n",
    "# data of mpnm results\n",
    "other_files = [file for file in all_files if \"result\" not in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result DataFrame:\n",
      "      Truck_id   Route_id             Origin        Destination  Total Time  \\\n",
      "0    Truck-100  Route-100  (425.0 0.0 194.5)   (625.0 0.0 50.0)     361.152   \n",
      "1    Truck-101  Route-101   (675.0 0.0 55.5)  (625.0 0.0 200.0)     348.368   \n",
      "2    Truck-102  Route-102  (175.0 0.0 194.5)    (375.0 0.0 0.0)     361.096   \n",
      "3    Truck-103  Route-103   (675.0 0.0 -5.5)  (125.0 0.0 200.0)     380.200   \n",
      "4    Truck-104  Route-104   (425.0 0.0 55.5)   (375.0 0.0 50.0)     378.624   \n",
      "..         ...        ...                ...                ...         ...   \n",
      "715   Truck-15   Route-15  (675.0 0.0 205.5)    (625.0 0.0 0.0)     349.912   \n",
      "716   Truck-16   Route-16   (675.0 0.0 55.5)  (375.0 0.0 200.0)     347.896   \n",
      "717   Truck-17   Route-17  (175.0 0.0 155.5)   (125.0 0.0 50.0)     371.592   \n",
      "718   Truck-18   Route-18  (425.0 0.0 105.5)    (375.0 0.0 0.0)     381.832   \n",
      "719   Truck-19   Route-19  (175.0 0.0 205.5)  (625.0 0.0 100.0)     398.296   \n",
      "\n",
      "     PickupSta AT  DropSta AT   rep                                 file_name  \n",
      "0          16.376      39.680  1rep    now_RoutePoints_20_LP_0_0_100_1rep.csv  \n",
      "1           6.936      36.400  1rep    now_RoutePoints_20_LP_0_0_100_1rep.csv  \n",
      "2          16.472      39.584  1rep    now_RoutePoints_20_LP_0_0_100_1rep.csv  \n",
      "3          32.536      42.632  1rep    now_RoutePoints_20_LP_0_0_100_1rep.csv  \n",
      "4          39.072      34.480  1rep    now_RoutePoints_20_LP_0_0_100_1rep.csv  \n",
      "..            ...         ...   ...                                       ...  \n",
      "715         7.104      37.720  2rep  prev_RoutePoints_20_LP_80_10_10_2rep.csv  \n",
      "716         6.928      35.800  2rep  prev_RoutePoints_20_LP_80_10_10_2rep.csv  \n",
      "717        30.200      36.328  2rep  prev_RoutePoints_20_LP_80_10_10_2rep.csv  \n",
      "718        35.896      40.856  2rep  prev_RoutePoints_20_LP_80_10_10_2rep.csv  \n",
      "719         6.976      86.256  2rep  prev_RoutePoints_20_LP_80_10_10_2rep.csv  \n",
      "\n",
      "[720 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "df = create_df(data_folder, result_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delay DataFrame:\n",
      "     Route_id  dist  delay_count   Truck_id  \\\n",
      "0         115    53            9  Truck-115   \n",
      "1         103    37            7  Truck-103   \n",
      "2         111    35           10  Truck-111   \n",
      "3         104    35            8  Truck-104   \n",
      "4         110    33            7  Truck-110   \n",
      "..        ...   ...          ...        ...   \n",
      "715        16    19            4   Truck-16   \n",
      "716         5    17            3    Truck-5   \n",
      "717        13    17            3   Truck-13   \n",
      "718         7    15            2    Truck-7   \n",
      "719        11    15            2   Truck-11   \n",
      "\n",
      "                                    file_name  \n",
      "0      now_RoutePoints_20_LP_0_0_100_1rep.csv  \n",
      "1      now_RoutePoints_20_LP_0_0_100_1rep.csv  \n",
      "2      now_RoutePoints_20_LP_0_0_100_1rep.csv  \n",
      "3      now_RoutePoints_20_LP_0_0_100_1rep.csv  \n",
      "4      now_RoutePoints_20_LP_0_0_100_1rep.csv  \n",
      "..                                        ...  \n",
      "715  prev_RoutePoints_20_LP_80_10_10_2rep.csv  \n",
      "716  prev_RoutePoints_20_LP_80_10_10_2rep.csv  \n",
      "717  prev_RoutePoints_20_LP_80_10_10_2rep.csv  \n",
      "718  prev_RoutePoints_20_LP_80_10_10_2rep.csv  \n",
      "719  prev_RoutePoints_20_LP_80_10_10_2rep.csv  \n",
      "\n",
      "[720 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "delay_df = distance_df(data_folder, other_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged DataFrame:\n",
      "      Truck_id  dist  delay_count  Total Time\n",
      "0      Truck-0    25            5     361.152\n",
      "1      Truck-1    19            4     348.368\n",
      "2      Truck-2    27            6     361.096\n",
      "3      Truck-3    37            7     380.200\n",
      "4      Truck-4    35            8     378.624\n",
      "..         ...   ...          ...         ...\n",
      "715  Truck-715    21            5     349.912\n",
      "716  Truck-716    19            4     347.896\n",
      "717  Truck-717    31            6     371.592\n",
      "718  Truck-718    35            8     381.832\n",
      "719  Truck-719    45            9     398.296\n",
      "\n",
      "[720 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Merge on 'file_name' and 'Truck_id'\n",
    "merged_df = pd.merge(df, delay_df, on=['Truck_id','file_name'])\n",
    "# merged_df = merged_df[['file_name', 'Truck_id', 'dist', 'delay_count', 'Total Time']]\n",
    "merged_df = merged_df[['dist', 'delay_count', 'Total Time']]\n",
    "\n",
    "# insert column at specific index location\n",
    "merged_df.insert(0, 'Truck_id', 'Truck-' + (merged_df.index).astype(str))\n",
    "print(\"merged DataFrame:\")\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to csv file\n",
    "# merged_df.to_csv('data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns = ['Truck_id', 'Completion_Time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder_path = 'Results_old_2'\n",
    "\n",
    "# all_data = pd.DataFrame()\n",
    "\n",
    "# # read subfolder of folder\n",
    "# all_folders = os.listdir(folder_path)\n",
    "\n",
    "# # read all files in subfolder\n",
    "# all_files = []\n",
    "# for folder in all_folders:\n",
    "#     _folder_path = os.path.join(folder_path, folder)\n",
    "#     # read only csv file\n",
    "#     csv_files = [file for file in os.listdir(_folder_path) if file.endswith('.csv')]\n",
    "    \n",
    "#     # read csv file and merge them\n",
    "#     for file in csv_files:\n",
    "#         file_path = os.path.join(_folder_path, file)\n",
    "#         # read csv file to dataframe and select columns\n",
    "#         _df = pd.read_csv(file_path)\n",
    "#         _df = _df[columns]\n",
    "#         _df['file_name'] = file\n",
    "#         _df['file_name'].replace('result-', '')\n",
    "#         _df['Truck_id_number'] = df['Truck_id'].apply(lambda x: int(x.split('-')[1]))\n",
    "        \n",
    "#         _df.loc[df['Truck_id_number'] >= 100]['file_name'] = _df['file_name'].replace()\n",
    "#         # replace file name to blank\n",
    "#         # _df['file_name'] = file.replace('result_', '')\n",
    "        \n",
    "#         # # check the number next to 'Truck-'\n",
    "#         # if int(_df['Truck_id'].str.extract(r'(\\d+)')) <= 100:\n",
    "#         #     _df['file_name']\n",
    "        \n",
    "#         # print(_df.head())\n",
    "        \n",
    "#         all_data = pd.concat([all_data, _df])\n",
    "        \n",
    "# all_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../Simulation/Assets/Data/old_data/Congestion_dh\\\\prev_10_now_10\\\\now_10\\\\now_RoutePoints_10_LP_0_0_100_43rep.csv', '../Simulation/Assets/Data/old_data/Congestion_dh\\\\prev_10_now_10\\\\now_10\\\\now_RoutePoints_10_LP_0_0_100_44rep.csv', '../Simulation/Assets/Data/old_data/Congestion_dh\\\\prev_10_now_10\\\\now_10\\\\now_RoutePoints_10_LP_0_0_100_45rep.csv', '../Simulation/Assets/Data/old_data/Congestion_dh\\\\prev_10_now_10\\\\now_10\\\\now_RoutePoints_10_LP_0_0_100_46rep.csv', '../Simulation/Assets/Data/old_data/Congestion_dh\\\\prev_10_now_10\\\\now_10\\\\now_RoutePoints_10_LP_0_0_100_47rep.csv']\n"
     ]
    }
   ],
   "source": [
    "# data of mpnm results\n",
    "import glob\n",
    "\n",
    "folder_path = '../Simulation/Assets/Data/old_data/Congestion_dh'\n",
    "\n",
    "all_files_df = pd.DataFrame()\n",
    "\n",
    "# read subfolder of folder not meta\n",
    "all_folders = [folder for folder in os.listdir(folder_path) if not folder.endswith('.meta')]\n",
    "\n",
    "all_files_list = []\n",
    "\n",
    "for folder in all_folders:\n",
    "    _folder_path = os.path.join(folder_path, folder)\n",
    "    \n",
    "    for subfolder in os.listdir(_folder_path):\n",
    "        # read all folder in subfolder not meta (now, prev)\n",
    "        _subfolders = [subfolder for subfolder in os.listdir(_folder_path) if not subfolder.endswith('.meta')]\n",
    "        \n",
    "        # read csv file in subfolder\n",
    "        for sub in _subfolders:\n",
    "            _subfolder_path = os.path.join(_folder_path, sub)\n",
    "            csv_file_path_list = glob.glob(os.path.join(_subfolder_path, \"*RoutePoints*.csv\"))\n",
    "            \n",
    "            # concat the list\n",
    "            all_files_list.extend(csv_file_path_list)\n",
    "\n",
    "print(all_files_list[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_df_2(_files_list):\n",
    "    delay_dfs = []\n",
    "\n",
    "    for file_path in _files_list:\n",
    "        _df = pd.read_csv(file_path)\n",
    "        _file_name = os.path.basename(file_path)\n",
    "        _df['coordinates'] = _df.apply(lambda row: (row['x'], row['y'], row['z']), axis=1)\n",
    "    \n",
    "        # Create 'is_delay_pos' column\n",
    "        _df['is_delay_pos'] = _df['coordinates'].apply(lambda coord: 1 if coord in delay_pos else 0)\n",
    "\n",
    "        if 'now' in _file_name:\n",
    "            _df['Route_id'] = _df['Route_id'] + 100\n",
    "        \n",
    "        # series to dataframe\n",
    "        dist_df = _df['Route_id'].value_counts().rename_axis('Route_id').reset_index(name='dist')\n",
    "        \n",
    "        # Count the number of times is_delay_pos is 1 for each Route_id\n",
    "        delay_count = _df[_df['is_delay_pos'] == 1].groupby('Route_id').size().reset_index(name='delay_count')\n",
    "        delay_count['Truck_id'] = 'Truck-' + delay_count['Route_id'].astype(str)\n",
    "\n",
    "        # get file name from file path\n",
    "        delay_count['file_name'] = _file_name\n",
    "        # Merge dist_df and delay_count\n",
    "        delay_count = pd.merge(dist_df, delay_count, on='Route_id')\n",
    "\n",
    "        delay_dfs.append(delay_count)\n",
    "\n",
    "    # Merge all DataFrames\n",
    "    delay_df = pd.concat(delay_dfs, ignore_index=True)\n",
    "    print(\"delay DataFrame:\")\n",
    "    print(delay_df)\n",
    "    \n",
    "    return delay_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delay DataFrame:\n",
      "        Route_id  dist  delay_count   Truck_id  \\\n",
      "0            100    53           11  Truck-100   \n",
      "1            104    41            7  Truck-104   \n",
      "2            105    37            5  Truck-105   \n",
      "3            107    37            7  Truck-107   \n",
      "4            109    37            7  Truck-109   \n",
      "...          ...   ...          ...        ...   \n",
      "249475         1    53            9    Truck-1   \n",
      "249476         2    43            8    Truck-2   \n",
      "249477         3    43           10    Truck-3   \n",
      "249478         0    27            6    Truck-0   \n",
      "249479         4    25            3    Truck-4   \n",
      "\n",
      "                                       file_name  \n",
      "0        now_RoutePoints_10_LP_0_0_100_43rep.csv  \n",
      "1        now_RoutePoints_10_LP_0_0_100_43rep.csv  \n",
      "2        now_RoutePoints_10_LP_0_0_100_43rep.csv  \n",
      "3        now_RoutePoints_10_LP_0_0_100_43rep.csv  \n",
      "4        now_RoutePoints_10_LP_0_0_100_43rep.csv  \n",
      "...                                          ...  \n",
      "249475  prev_RoutePoints_5_LP_80_10_10_60rep.csv  \n",
      "249476  prev_RoutePoints_5_LP_80_10_10_60rep.csv  \n",
      "249477  prev_RoutePoints_5_LP_80_10_10_60rep.csv  \n",
      "249478  prev_RoutePoints_5_LP_80_10_10_60rep.csv  \n",
      "249479  prev_RoutePoints_5_LP_80_10_10_60rep.csv  \n",
      "\n",
      "[249480 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "df = distance_df_2(all_files_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to csv file\n",
    "df.to_csv('results_old_2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "purify",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
